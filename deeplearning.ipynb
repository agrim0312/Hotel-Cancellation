{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup plotting\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "# Set Matplotlib defaults\n",
    "plt.rc('figure', autolayout=True)\n",
    "plt.rc('axes', labelweight='bold', labelsize='large',\n",
    "       titleweight='bold', titlesize=18, titlepad=10)\n",
    "plt.rc('animation', html='html5')\n",
    "\n",
    "# Setup feedback system\n",
    "from learntools.core import binder\n",
    "binder.bind(globals())\n",
    "from learntools.deep_learning_intro.ex6 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, load the Hotel Cancellations dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "hotel = pd.read_csv('../input/dl-course-data/hotel.csv')\n",
    "\n",
    "X = hotel.copy()\n",
    "y = X.pop('is_canceled')\n",
    "\n",
    "X['arrival_date_month'] = \\\n",
    "    X['arrival_date_month'].map(\n",
    "        {'January':1, 'February': 2, 'March':3,\n",
    "         'April':4, 'May':5, 'June':6, 'July':7,\n",
    "         'August':8, 'September':9, 'October':10,\n",
    "         'November':11, 'December':12}\n",
    "    )\n",
    "\n",
    "features_num = [\n",
    "    \"lead_time\", \"arrival_date_week_number\",\n",
    "    \"arrival_date_day_of_month\", \"stays_in_weekend_nights\",\n",
    "    \"stays_in_week_nights\", \"adults\", \"children\", \"babies\",\n",
    "    \"is_repeated_guest\", \"previous_cancellations\",\n",
    "    \"previous_bookings_not_canceled\", \"required_car_parking_spaces\",\n",
    "    \"total_of_special_requests\", \"adr\",\n",
    "]\n",
    "features_cat = [\n",
    "    \"hotel\", \"arrival_date_month\", \"meal\",\n",
    "    \"market_segment\", \"distribution_channel\",\n",
    "    \"reserved_room_type\", \"deposit_type\", \"customer_type\",\n",
    "]\n",
    "\n",
    "transformer_num = make_pipeline(\n",
    "    SimpleImputer(strategy=\"constant\"), # there are a few missing values\n",
    "    StandardScaler(),\n",
    ")\n",
    "transformer_cat = make_pipeline(\n",
    "    SimpleImputer(strategy=\"constant\", fill_value=\"NA\"),\n",
    "    OneHotEncoder(handle_unknown='ignore'),\n",
    ")\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "    (transformer_num, features_num),\n",
    "    (transformer_cat, features_cat),\n",
    ")\n",
    "\n",
    "# stratify - make sure classes are evenlly represented across splits\n",
    "X_train, X_valid, y_train, y_valid = \\\n",
    "    train_test_split(X, y, stratify=y, train_size=0.75)\n",
    "\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_valid = preprocessor.transform(X_valid)\n",
    "\n",
    "input_shape = [X_train.shape[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Define Model\n",
    "The model we'll use this time will have both batch normalization and dropout layers. To ease reading we've broken the diagram into blocks, but you can define it layer by layer as usual.\n",
    "\n",
    "Define a model with an architecture given by this diagram:\n",
    "\n",
    "Diagram of network architecture: BatchNorm, Dense, BatchNorm, Dropout, Dense, BatchNorm, Dropout, Dense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.BatchNormalization(input_shape = input_shape),\n",
    "    layers.Dense(256,activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(256,activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(1,activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "2) Add Optimizer, Loss, and Metric\n",
    "Now compile the model with the Adam optimizer and binary versions of the cross-entropy loss and accuracy metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",loss='binary_crossentropy',metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, run this cell to train the model and view the learning curves. It may run for around 60 to 70 epochs, which could take a minute or two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    patience=5,\n",
    "    min_delta=0.001,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    batch_size=512,\n",
    "    epochs=200,\n",
    "    callbacks=[early_stopping],\n",
    ")\n",
    "\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.loc[:, ['loss', 'val_loss']].plot(title=\"Cross-entropy\")\n",
    "history_df.loc[:, ['binary_accuracy', 'val_binary_accuracy']].plot(title=\"Accuracy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
